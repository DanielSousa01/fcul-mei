{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c4b3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "\n",
    "N = 100000\n",
    "FEATURES = 10\n",
    "\n",
    "cols = \"abcdefghijkmnopqrstuv\"\n",
    "columns = list(cols)[:FEATURES]\n",
    "\n",
    "x = np.random.rand(N, FEATURES)\n",
    "\n",
    "df = pd.DataFrame(x, columns = columns)\n",
    "df[\"y\"] = np.sin(df[\"a\"].values) + np.cos(df[\"b\"].values) + np.random.rand(N) * 0.001\n",
    "\n",
    "df.to_csv(\"data.csv\")\n",
    "\n",
    "\n",
    "unary_funs = [\"sinf\", \"cosf\", \"sqrtf\"]\n",
    "operators = [\"+\", \"-\"]\n",
    "\n",
    "def random_program(depth=4):\n",
    "    r = rd.randint(0,100)\n",
    "    if depth == 0 or r < 30:\n",
    "        c = rd.choice(columns)\n",
    "        return f\"_{c}_\"\n",
    "    elif r < 80:\n",
    "        c = rd.choice(unary_funs)\n",
    "        r = random_program(depth-1)\n",
    "        return f\"{c}({r})\"\n",
    "    else:\n",
    "        c = rd.choice(operators)\n",
    "        r1 = random_program(depth-1)\n",
    "        r2 = random_program(depth-1)\n",
    "        return f\"({r1}) {c} ({r2})\"\n",
    "\n",
    "\n",
    "with open(\"functions.txt\", \"w\") as f:\n",
    "    for _ in range(1000):\n",
    "        f.write(random_program() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d6bd0",
   "metadata": {},
   "source": [
    "# Sequential Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9278f6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8092803992473381 _e_\n",
      "1 - Time taken: 0.001703023910522461 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Time taken: 2.3751702308654785 seconds\n",
      "0.0383211840124654 (sqrtf(sqrtf(sqrtf(_i_)))) + (_a_)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(\"data.csv\", index_col=0)\n",
    "\n",
    "funs = [ line.strip() for line in open(\"functions.txt\").readlines() ]\n",
    "\n",
    "def score(line):\n",
    "    for u in [\"sinf\", \"cosf\", \"tanf\", \"sqrtf\", \"expf\"]:\n",
    "        line = line.replace(u, f\"np.{u[:-1]}\")\n",
    "    for c in df.columns:\n",
    "        line = line.replace(f\"_{c}_\", f\"(df[\\\"{c}\\\"].values)\")\n",
    "    a = eval(line)\n",
    "    b = df[\"y\"]\n",
    "    e = np.square(np.subtract(a, b)).mean()\n",
    "    return e\n",
    "\n",
    "l = funs[0]\n",
    "first_start = time.time()\n",
    "print(score(l), l)\n",
    "first_end = time.time()\n",
    "print(f\"1 - Time taken: {first_end - first_start} seconds\")\n",
    "\n",
    "secound_start = time.time()\n",
    "r = min([ (score(line), line) for line in funs ])\n",
    "secound_end = time.time()\n",
    "print(f\"2 - Time taken: {secound_end - secound_start} seconds\")\n",
    "print(f\"{r[0]} {r[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515e949",
   "metadata": {},
   "source": [
    "# Prallel Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "funs = [line.strip() for line in open(\"functions.txt\").readlines()]\n",
    "\n",
    "# Prepare data for GPU\n",
    "y_true = df.iloc[:, -1].values.astype(np.float32)\n",
    "n_samples = len(y_true)\n",
    "input_cols = df.columns[:-1]\n",
    "n_features = len(input_cols)\n",
    "\n",
    "# Create feature matrix\n",
    "X = df[input_cols].values.astype(np.float32)\n",
    "\n",
    "# Transfer data to GPU\n",
    "d_X = cuda.to_device(X)\n",
    "d_y_true = cuda.to_device(y_true)\n",
    "\n",
    "def translate_function(func_str, col_names):\n",
    "    \"\"\"Translate function string to CUDA-compatible code\"\"\"\n",
    "    result = func_str\n",
    "    \n",
    "    # Replace math functions\n",
    "    replacements = {\n",
    "        'sinf': 'math.sin',\n",
    "        'cosf': 'math.cos',\n",
    "        'tanf': 'math.tan',\n",
    "        'sqrtf': 'math.sqrt',\n",
    "        'expf': 'math.exp',\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        result = result.replace(old, new)\n",
    "    \n",
    "    # Replace column references with array indexing\n",
    "    for idx, col in enumerate(col_names):\n",
    "        result = result.replace(f'_{col}_', f'X[i, {idx}]')\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_kernel_code(func_expr):\n",
    "    \"\"\"Generate CUDA kernel code as string for dynamic compilation\"\"\"\n",
    "    kernel_code = f'''\n",
    "@cuda.jit\n",
    "def compute_kernel(X, y_pred):\n",
    "    i = cuda.grid(1)\n",
    "    if i < X.shape[0]:\n",
    "        y_pred[i] = {func_expr}\n",
    "'''\n",
    "    return kernel_code\n",
    "\n",
    "def create_mse_kernel():\n",
    "    \"\"\"Kernel to compute MSE on GPU\"\"\"\n",
    "    @cuda.jit\n",
    "    def mse_kernel(y_pred, y_true, squared_errors):\n",
    "        i = cuda.grid(1)\n",
    "        if i < y_pred.shape[0]:\n",
    "            diff = y_pred[i] - y_true[i]\n",
    "            squared_errors[i] = math.pow(diff, 2)\n",
    "    return mse_kernel\n",
    "\n",
    "# Create MSE kernel\n",
    "mse_kernel = create_mse_kernel()\n",
    "\n",
    "def score_gpu_single(func_str, d_X, d_y_true, col_names):\n",
    "    \"\"\"Score a single function on GPU\"\"\"\n",
    "    try:\n",
    "        # Translate function\n",
    "        cuda_expr = translate_function(func_str, col_names)\n",
    "        \n",
    "        # Generate and compile kernel dynamically\n",
    "        kernel_code = create_kernel_code(cuda_expr)\n",
    "        local_namespace = {'cuda': cuda, 'math': math}\n",
    "        exec(kernel_code, local_namespace)\n",
    "        compute_kernel = local_namespace['compute_kernel']\n",
    "        \n",
    "        # Allocate output arrays on GPU\n",
    "        d_y_pred = cuda.device_array(n_samples, dtype=np.float32)\n",
    "        d_squared_errors = cuda.device_array(n_samples, dtype=np.float32)\n",
    "        \n",
    "        # Configure kernel launch\n",
    "        threads_per_block = 256\n",
    "        blocks_per_grid = (n_samples + threads_per_block - 1) // threads_per_block\n",
    "        \n",
    "        # Launch prediction kernel\n",
    "        compute_kernel[blocks_per_grid, threads_per_block](d_X, d_y_pred)\n",
    "        \n",
    "        # Launch MSE kernel\n",
    "        mse_kernel[blocks_per_grid, threads_per_block](d_y_pred, d_y_true, d_squared_errors)\n",
    "        \n",
    "        # Copy result back and compute mean\n",
    "        squared_errors = d_squared_errors.copy_to_host()\n",
    "        mse = np.mean(squared_errors)\n",
    "        \n",
    "        return mse\n",
    "    except Exception as e:\n",
    "        # Return infinity for invalid functions\n",
    "        return float('inf')\n",
    "\n",
    "def score_gpu_batch(funcs, d_X, d_y_true, col_names, batch_size=100):\n",
    "    \"\"\"Score multiple functions using task parallelism\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Process in batches to manage GPU memory\n",
    "    for i in range(0, len(funcs), batch_size):\n",
    "        batch = funcs[i:i+batch_size]\n",
    "        batch_results = []\n",
    "        \n",
    "        for func_str in batch:\n",
    "            mse = score_gpu_single(func_str, d_X, d_y_true, col_names)\n",
    "            batch_results.append((mse, func_str))\n",
    "        \n",
    "        results.extend(batch_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Benchmark: Sequential CPU version\n",
    "print(\"=\" * 60)\n",
    "print(\"SEQUENTIAL CPU VERSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def score_cpu(line):\n",
    "    \"\"\"Original CPU scoring function\"\"\"\n",
    "    for u in [\"sinf\", \"cosf\", \"tanf\", \"sqrtf\", \"expf\"]:\n",
    "        line = line.replace(u, f\"np.{u[:-1]}\")\n",
    "    for c in df.columns[:-1]:\n",
    "        line = line.replace(f\"_{c}_\", f\"(df[\\\"{c}\\\"].values)\")\n",
    "    try:\n",
    "        a = eval(line)\n",
    "        b = df[\"y\"]\n",
    "        e = np.square(np.subtract(a, b)).mean()\n",
    "        return e\n",
    "    except:\n",
    "        return float('inf')\n",
    "\n",
    "start_cpu = time.time()\n",
    "cpu_results = [(score_cpu(line), line) for line in funs]\n",
    "cpu_best = min(cpu_results)\n",
    "end_cpu = time.time()\n",
    "\n",
    "print(f\"First function: {cpu_results[0][0]:.6f} - {cpu_results[0][1]}\")\n",
    "print(f\"Best function:  {cpu_best[0]:.6f} - {cpu_best[1]}\")\n",
    "print(f\"Time: {end_cpu - start_cpu:.4f} seconds\")\n",
    "print()\n",
    "\n",
    "# GPU Version\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU VERSION (Data + Task Parallelism)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_gpu = time.time()\n",
    "gpu_results = score_gpu_batch(funs, d_X, d_y_true, input_cols)\n",
    "gpu_best = min(gpu_results)\n",
    "end_gpu = time.time()\n",
    "\n",
    "print(f\"First function: {gpu_results[0][0]:.6f} - {gpu_results[0][1]}\")\n",
    "print(f\"Best function:  {gpu_best[0]:.6f} - {gpu_best[1]}\")\n",
    "print(f\"Time: {end_gpu - start_gpu:.4f} seconds\")\n",
    "print()\n",
    "\n",
    "# Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CPU Time:       {end_cpu - start_cpu:.4f} seconds\")\n",
    "print(f\"GPU Time:       {end_gpu - start_gpu:.4f} seconds\")\n",
    "print(f\"Speedup:        {(end_cpu - start_cpu) / (end_gpu - start_gpu):.2f}x\")\n",
    "print(f\"Functions eval: {len(funs)}\")\n",
    "print(f\"Data points:    {n_samples}\")\n",
    "print()\n",
    "\n",
    "# Parallelism analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"PARALLELISM ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Data Parallelism:\")\n",
    "print(f\"  - Each function evaluated across {n_samples} samples in parallel\")\n",
    "print(f\"  - Grid size: {(n_samples + 255) // 256} blocks Ã— 256 threads\")\n",
    "print()\n",
    "print(\"Task Parallelism:\")\n",
    "print(f\"  - {len(funs)} functions processed independently\")\n",
    "print(f\"  - Dynamic kernel generation per function\")\n",
    "print(f\"  - Batched execution to optimize GPU memory usage\")\n",
    "print()\n",
    "print(\"GPU Optimizations:\")\n",
    "print(\"  - All data transferred to GPU once (X, y_true)\")\n",
    "print(\"  - MSE computation parallelized on GPU\")\n",
    "print(\"  - Reduced CPU-GPU transfers (only final MSE value)\")\n",
    "print(\"  - Float32 precision for better GPU performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
