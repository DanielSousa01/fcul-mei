\chapter{Implementation}
\label{cap:implementation}

\section{Kotlin Implementation}

Four variants of the GA were implemented in Kotlin, exploring different concurrency models:

\begin{itemize}
    \item \textbf{Sequential:} A baseline single-threaded implementation where evaluation, selection, crossover, and mutation operations execute sequentially without any parallelization.
    
    \item \textbf{Coroutines:} Parallelization is achieved by launching coroutines using \texttt{launch} on \texttt{Dispatchers.Default}. The population is divided into chunks, and work is distributed across available threads. Synchronization is handled via \texttt{joinAll()} on the launched jobs. Race conditions are prevented by either updating distinct indices or writing into a preallocated new population array.
    
    \item \textbf{Channels:} This variant leverages \texttt{kotlinx.coroutines.channels.Channel} to establish communication between producer and consumer coroutines. Chunks of work (sent as copies) are transmitted through channels. A pool of consumer coroutines reads from the channel until it is closed by the producer upon completion of all work.
    
    \item \textbf{Actors (Akka):} Each operation is encapsulated within an actor. A master actor coordinates the workflow by sending population snapshots or copies to worker actors, which process assigned chunks and return results. Load balancing is achieved through routers such as \texttt{RoundRobinPool} to distribute work evenly across workers.
\end{itemize}

\section{Go Implementation}

Four implementations were developed in Go, each utilizing different concurrency primitives:

\begin{itemize}
    \item \textbf{Sequential:} A baseline single-threaded implementation that executes all operations in sequential order without parallelization.
    
    \item \textbf{Goroutines + WaitGroups:} The population is partitioned into chunks, and a \texttt{computeChunk} helper function launches one goroutine per chunk. Each goroutine maintains its own \texttt{rand.Rand} instance (seeded with the current time plus a index offset) to ensure thread-safe random number generation. A \texttt{sync.WaitGroup} synchronizes completion of all goroutines before proceeding to the next step.
    
    \item \textbf{Channels + WaitGroups:} This variant implements worker pools that consume messages from a work channel and send results to a result channel. The master goroutine sends deep-copied chunks into the work channel and collects processed chunks from the result channel. A \texttt{sync.WaitGroup} ensures that result channels are properly closed after all workers finish. Elitism is preserved during population reassembly.
    
    \item \textbf{Actors (Proto Actor):} Each GA operation is encapsulated within dedicated actors (\texttt{FitnessActor}, \texttt{CrossoverActor}, \texttt{MutateActor}). The master actor spawns pools of worker actors and uses request-future patterns to dispatch work and aggregate responses. Each actor maintains its own random number generator instance to avoid contention.
\end{itemize}

\section{Rust Implementation}

Three variants were implemented in Rust, showcasing different approaches to asynchronous parallelism:

\begin{itemize}
    \item \textbf{Sequential:} A baseline single-threaded implementation serving as the performance reference point.
    
    \item \textbf{Async Tasks:} The population is partitioned into chunks, and \texttt{tokio::spawn} is used to create asynchronous tasks for processing each chunk. Task handles are collected and awaited to synchronize stage completion. To minimize memory copying overhead, the implementation passes raw pointers into task closures and performs in-place mutation within \texttt{unsafe} blocks. While this approach yields excellent throughput, it requires strict guarantees about non-overlapping writes and careful management of the underlying \texttt{Vec} lifetime.
    
    \item \textbf{Channels:} The channel-based design uses \texttt{tokio::sync::mpsc} channels to implement a pipeline architecture. Producer tasks push work items into channels, a pool of worker tasks consumes and processes them, and results are forwarded to a collector. Bounded channels provide natural backpressure and improve reasoning about pipeline behavior, making the design more amenable to distributed setups. However, this approach incurs some overhead from message copying and coordination.
\end{itemize}

