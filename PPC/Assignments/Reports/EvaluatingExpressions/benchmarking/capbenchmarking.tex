\chapter{Benchmarking}\label{cap:benchmarking}

This chapter outlines the benchmarking methodology and results for evaluating the performance of GPU-accelerated mathematical expression evaluation using PyTorch compared to a CPU-based implementation.

\section{Scope and Method}
\begin{itemize}
	\item Compare CPU (sequential NumPy loop) vs GPU (batched PyTorch, \texttt{TASK\_BATCH=32}).
	\item Measure: total runtime per dataset, average time per function (total $/$ $n_{\mathrm{functions}}$), best MSE expression, and speedup (CPU time $/$ GPU time).
	\item Datasets: generated by \texttt{generate\_inputs.py} (rows, features, and function count per case).
\end{itemize}

\section{Environment}
\begin{itemize}
	\item Hardware: Codelab GPU instance.
	\item Device selected by \texttt{torch.device("cuda" if torch.cuda.is\_available() else "cpu")}.
\end{itemize}

\section{Results}
\begin{table}[h]
	\centering
	\caption{Benchmark Results Summary}
	\begin{tabular}{lrrrrr}
		\hline
		\textbf{Test Case} & \textbf{Rows} & \textbf{Funcs} & \textbf{CPU (s)} & \textbf{GPU (s)} & \textbf{Speedup} \\
		\hline
		large\_heavy     & 100{,}000 & 2{,}000 & 5.5208  & 0.4816 & 11.46 \\
		large\_moderate  & 50{,}000  & 1{,}000 & 1.3574  & 0.1545 & 8.79  \\
		large\_standard  & 100{,}000 & 1{,}000 & 2.4130  & 0.2855 & 8.45  \\
		medium\_balanced & 10{,}000  & 500    & 0.2361  & 0.0246 & 9.61  \\
		medium\_complex  & 20{,}000  & 1{,}000 & 0.6445  & 0.0448 & 14.39 \\
		small\_medium    & 5{,}000   & 200    & 0.0674  & 0.0062 & 10.96 \\
		small\_simple    & 1{,}000   & 100    & 0.0321  & 0.0031 & 10.33 \\
		xlarge\_extreme  & 200{,}000 & 2{,}000 & 10.9501 & 0.5911 & 18.53 \\
		\hline
	\end{tabular}
\end{table}
